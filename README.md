# ğŸ“ Master-Seminar: AI for Vision-Language Models in Medical Imaging (IN2107, IN45069)

## Organizer: Chair of Computational Imaging and AI in Medicine (CompAI)
<p align="center">
    ğŸ‘©â€ğŸ« <strong><a href="https://compai-lab.github.io/author/julia-a.-schnabel/">Prof. Julia A. Schnabel</a></strong> &nbsp;&nbsp;â”‚
    ğŸ§‘â€ğŸ”¬ <strong><a href="https://cosmin-bercea.com/">Dr. Cosmin I. Bercea</a></strong> &nbsp;&nbsp;â”‚
    ğŸ‘©â€ğŸ’¼ <strong><a href="https://lijunrio.github.io/junli/">Jun Li</a></strong> &nbsp;&nbsp;â”‚
    ğŸ‘©â€ğŸ’¼ <strong><a href="https://compai-lab.github.io/author/ha-young-kim/">Ha Young Kim</a></strong>
</p>
<p align="center">
    ğŸ›ï¸ <strong><a href="https://compai-lab.github.io/">CompAI & IML Lab</a></strong>
</p>
<p align="center">
    <img src="images\compai.png" alt="Chair Members" width="800"/>
</p>

## ğŸ“˜ Seminar Overview

The **Master-Seminar on AI for Vision-Language Models in Medical Imaging** introduces students to the fundamentals of Vision-Language Models (VLMs) and their applications in the medical domain.

### Key Components:
- ğŸ“š **Student presentations** on the state-of-the-art (SOTA) VLM papers
- ğŸ§‘â€ğŸ« **Talks from invited researchers and professors**
- ğŸ› ï¸ **Hands-on projects** exploring VLMs in real medical data

Our goal is to **foster curiosity**, **bridge modalities**, and **inspire new research** at the intersection of AI and medical imaging.

---

## ğŸ“š Paper List

| #  | **Title**                                                                                          | **Time**     | **Link**                                               | **Topics**                             |
|----|----------------------------------------------------------------------------------------------------|--------------|--------------------------------------------------------|----------------------------------------|
| 1  | Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning                                          | 27 Mar 2025  | [arXiv](https://arxiv.org/abs/2503.20752)              | Visual Reasoning, Reinforcement Learning |
| 2  | LIMO: Less is More for Reasoning                                                                  | 5 Feb 2025   | [arXiv](https://arxiv.org/abs/2502.03387)              | Efficient Reasoning, LLMs              |
| 3  | Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases                          | 6 Mar 2025   | [arXiv](https://arxiv.org/abs/2503.04691)              | Clinical Reasoning, Evaluation         |
| 4  | Demystifying Long Chain-of-Thought Reasoning in LLMs                                              | 5 Feb 2025   | [arXiv](https://arxiv.org/abs/2502.03373)              | CoT Analysis, LLMs                     |
| 5  | Chain-of-Thought Prompting Elicits Reasoning in Large Language Models                             | 10 Jan 2023  | [arXiv](https://arxiv.org/abs/2201.11903)              | Prompt Engineering, Reasoning          |
| 6  | Visual-RFT: Visual Reinforcement Fine-Tuning                                                      | 3 Mar 2025   | [arXiv](https://arxiv.org/abs/2503.01785)              | Vision-Language, RL                    |
| 7  | RadVLM: A Multitask Conversational Vision-Language Model for Radiology                            | 18 Dec 2024  | [arXiv](https://arxiv.org/abs/2502.03333)              | Radiology, VLM                         |
| 8  | CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation                              | 22 Jan 2024  | [arXiv](https://arxiv.org/abs/2401.12208)              | Medical VLMs, X-ray                    |
| 9  | MAIRA-2: Grounded Radiology Report Generation                                                     | 6 Jun 2024   | [arXiv](https://arxiv.org/abs/2406.04449)              | Report Generation, Radiology           |
| 10 | Qwen2.5-VL Technical Report                                                                       | 19 Feb 2025  | [arXiv](https://arxiv.org/abs/2502.13923)              | Foundation Model, VLM                  |
| 11 | LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day              | 1 Jun 2023   | [arXiv](https://arxiv.org/abs/2306.00890)              | Medical VLMs                           |
| 12 | Towards Evaluating and Building Versatile Large Language Models for Medicine                     | 5 Sep 2024   | [arXiv](https://www.nature.com/articles/s41746-024-01390-4) | Medical LLMs, Generalist Models        |
| 13 | Can Modern LLMs Act as Agent Cores in Radiology Environments?                                      | 8 Apr 2025   | [arXiv](https://arxiv.org/pdf/2412.09529)              | Agents, Radiology                      |
| 14 | A Large Model for Non-Invasive and Personalized Management of Breast Cancer from MRI              | 17 Apr 2025  | [arXiv](https://www.nature.com/articles/s41467-025-58798-z) | Breast Cancer, MRI, Personalized AI    |
| 15 | MedRAX: Medical Reasoning Agent for Chest X-ray                                                   | 4 Feb 2025   | [arXiv](https://arxiv.org/abs/2502.02673)              | X-ray Reasoning, Agents                |
| 16 | MDTeamGPT: A Self-Evolving LLM-based Multi-Agent Framework for Medical Consultation               | 18 Mar 2025  | [arXiv](https://arxiv.org/abs/2503.13856)              | Multi-Agent, Healthcare AI             |
| 17 | Premise Order Matters in Reasoning with Large Language Models                                     | 14 Feb 2024  | [arXiv](https://arxiv.org/abs/2402.08939)              | Logical Reasoning, Prompt Order        |
| 18 | A Scalable Framework for Evaluating Health Language Models                                        | 30 Mar 2025  | [arXiv](https://arxiv.org/abs/2503.23339)              | Evaluation, Health LLMs                |

> **Note**: If you are interested in a paper that is not included in the list above, feel free to email us about the paper, and we will be happy to consider it!

---

## ğŸ“ Student Presentations

Each student is assigned a paper to present and implement a related project. GitHub links will be updated as projects are finalized.

| **Student Name**          | **Paper Title**                                                                 | **GitHub Repository**                 |
|---------------------------|----------------------------------------------------------------------------------|---------------------------------------|
| Jun Li                     | Enhancing Abnormality Grounding for Vision-Language Models with Knowledge Descriptions | [Repo](https://github.com/LijunRio/example_for_seminar) |
| Francesco Vaccaro          |                                                                                  | [Repo](#)                             |
| Dominik Garstenauer        |                                                                                  | [Repo](#)                             |
| Linfeng Guo                |                                                                                  | [Repo](#)                             |
| Fatih Ibrahim Ã–zlÃ¼gedik    |                                                                                  | [Repo](#)                             |
| Tuna Karacan               |                                                                                  | [Repo](#)                             |
| Jingyi He                  |                                                                                  | [Repo](#)                             |
| Bivek Panthi               |                                                                                  | [Repo](#)                             |
| Philipp RÃ¶ssel             |                                                                                  | [Repo](#)                             |
| Luis Schmid                |                                                                                  | [Repo](#)                             |
| Radoslav M. Yankov         |                                                                                  | [Repo](#)                             |
| Abdullah Utku Yertutan     |                                                                                  | [Repo](#)                             |

---

### ğŸ“¬ Contact Information

For any seminar-related questions, feel free to reach out (remember to CC all of us):  
- ğŸ‘¨â€ğŸ’» **Dr. Cosmin I. Bercea** â€“ [cosmin.bercea@tum.de](mailto:cosmin.bercea@tum.de)  
- ğŸ‘©â€ğŸ’¼ **Jun Li** â€“ [june.li@tum.de](mailto:june.li@tum.de)  
- ğŸ‘©â€ğŸ’¼ **Ha Young Kim** â€“ [hayoung.kim@tum.de](mailto:hayoung.kim@tum.de)

---

### ğŸ”— Additional Resources

Learn more about our research and stay updated with the latest developments from our lab:  
ğŸŒ **[CompAI Lab â€“ Computational Imaging & AI in Medicine](#)**
